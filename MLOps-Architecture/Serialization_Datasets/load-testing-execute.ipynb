{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955f5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file_to_docker(file_path, docker_path):\n",
    "    \"\"\"Copy a file from local to GCP VM and then into the Docker container.\"\"\"\n",
    "    filename = file_path.split(\"/\")[-1] if \"/\" in file_path else file_path.split(\"\\\\\")[-1]\n",
    "    # Copy file to VM\n",
    "    !gcloud compute scp --zone=us-central1-a {file_path} load-testing-instance:/home/adilm\n",
    "    # Copy file from VM to Docker container\n",
    "    copy_command = f\"docker cp /home/adilm/{filename} load-testing-container:{docker_path}\"\n",
    "    !gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\"{copy_command}\"\n",
    "\n",
    "def run_docker_command(inner_command):\n",
    "    \"\"\"\n",
    "    Run a command inside load-testing-container on the GCP VM via SSH using docker exec.\n",
    "    \"\"\"\n",
    "    docker_exec_template = \"docker exec load-testing-container bash -c '{cmd}'\"\n",
    "    docker_command = docker_exec_template.format(cmd=inner_command)\n",
    "    ssh_command = f\"gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\\\"{docker_command}\\\"\"\n",
    "    !{ssh_command}\n",
    "\n",
    "def copy_dir_to_docker(dir_path, docker_path):\n",
    "    \"\"\"Copy a directory from local to GCP VM and then into the Docker container.\"\"\"\n",
    "    dir_name = dir_path.split(\"/\")[-1] if \"/\" in dir_path else dir_path.split(\"\\\\\")[-1]\n",
    "    # Clean up the VM directory \n",
    "    rm_command = f\"rm -rf /home/adilm/{dir_name}\"  # Clean up the VM directory after copying\n",
    "    docker_rm_command = f\"docker exec load-testing-container rm -rf {docker_path}{dir_name}\"  # Clean up the Docker directory\n",
    "    !gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\"{rm_command}\"\n",
    "    !gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\"{docker_rm_command}\"\n",
    "    # Copy directory to VM\n",
    "    print(f\"gcloud compute scp --zone=us-central1-a --recurse {dir_path} load-testing-instance:/home/adilm/\")\n",
    "    !gcloud compute scp --zone=us-central1-a --recurse {dir_path} load-testing-instance:/home/adilm/\n",
    "    # Copy directory from VM to Docker container\n",
    "    copy_command = f\"docker cp /home/adilm/{dir_name} load-testing-container:{docker_path}\"\n",
    "    !gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\"{copy_command}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ddec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN LOAD TESTING VM\n",
    "vm_name = \"load-testing-instance\"\n",
    "snapshot_name = \"load-testing-instance-snapshot\"\n",
    "zone = \"us-central1-a\"\n",
    "!gcloud compute instances create {vm_name} --zone={zone} --disk=name={snapshot_name},boot=yes,auto-delete=yes --machine-type=e2-standard-8\n",
    "!gcloud compute firewall-rules create allow-all --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=all --source-ranges=0.0.0.0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9937c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VM load-testing-instance is running.\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF VM IS RUNNING\n",
    "vm_status = !gcloud compute instances describe {vm_name} --zone={zone} --format=\"get(status)\"\n",
    "if vm_status[0] == \"RUNNING\":\n",
    "    print(f\"VM {vm_name} is running.\")\n",
    "else:\n",
    "    print(f\"VM {vm_name} is not running. Current status: {vm_status[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49879c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN LOAD TESTING CONTAINER\n",
    "docker_command = \"docker run -d --name load-testing-container auliadil/load-testing-rodrigues:v1 tail -f /dev/null\"\n",
    "gcloud_template = \"gcloud compute ssh standalone-load-tester --zone=us-central1-a\"\n",
    "!{gcloud_template} --command=\"{docker_command}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e265685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF CONTAINER IS RUNNING\n",
    "container_status = !gcloud compute ssh load-testing-instance --zone={zone} --command=\"docker ps -q --filter 'name=load-testing-container'\"\n",
    "if container_status:\n",
    "    print(\"Container is running.\")\n",
    "else:\n",
    "    print(\"Container is not running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY FILE\n",
    "copy_file_to_docker(\"../Serialization_Datasets/locust-testing.py\", \"/app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/\")\n",
    "# copy_file_to_docker(\"../Serialization_Datasets/check-kafka-lag.py\", \"/app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/\")\n",
    "# copy_dir_to_docker('C:/Users/adilm/AppData/Roaming/gcloud', \"/root/.config/gcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdddd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check copy file\n",
    "path = \"/app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets\"\n",
    "run_docker_command(\"cat \" + path + \"/locust-testing.py\")\n",
    "# run_docker_command(\"cat \" + path + \"/check-kafka-lag.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36600818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                              READY   STATUS    RESTARTS   AGE\n",
      "api-inferencia-6f47cb7df8-92lbg   1/1     Running   0          7h6m\n",
      "api-inferencia-6f47cb7df8-dxnqj   1/1     Running   0          7h6m\n",
      "api-inferencia-6f47cb7df8-sp8t6   1/1     Running   0          7h6m\n",
      "api-inferencia-6f47cb7df8-tn9f8   1/1     Running   0          7h6m\n",
      "api-update-794765cdd7-wwk5f       1/1     Running   0          7h6m\n",
      "mlflow-cb7f6b8b-59vjb             1/1     Running   0          7h6m\n"
     ]
    }
   ],
   "source": [
    "# Check GCloud\n",
    "# projects = !gcloud config get-value project\n",
    "# set_project_command = f\"gcloud config set project {projects[0]}\"\n",
    "# get_kubectl_command = \"gcloud container clusters get-credentials two-node-cluster --zone us-central1-a\"\n",
    "# run_docker_command(set_project_command)\n",
    "# run_docker_command(get_kubectl_command)\n",
    "run_docker_command(\"kubectl get pods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2213eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "locust_path = \"/app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/locust-testing.py\"\n",
    "check_kafka_lag_dir_path = \"/app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets\"\n",
    "locust_command = f\"locust -f {locust_path} --users 50 --spawn-rate 50 --headless --csv=result_testing\"\n",
    "run_docker_command(f\"cd {check_kafka_lag_dir_path} && nohup python3 check-kafka-lag.py > kafka_lag.log 2>&1 &\")\n",
    "# run_docker_command(f\"cd /app/large-scale-online-learning/ && source ../.python-venv/bin/activate && nohup {locust_command} > locust.log 2>&1 &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "812ce011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root        3820  0.0  0.0   4324   236 ?        S    14:00   0:00 bash -c cd /app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets && nohup python3 check-kafka-lag.py > kafka_lag.log 2>&1 &\n",
      "root        3821  0.2  0.0  90664 12144 ?        Sl   14:00   0:00 python3 check-kafka-lag.py\n",
      "root        3866 75.0  0.0   4324  3528 ?        Ss   14:00   0:00 bash -c ps aux | grep check-kafka-lag.py\n",
      "root        3873  0.0  0.0   3528  1708 ?        S    14:00   0:00 grep check-kafka-lag.py\n",
      "root        3794  0.0  0.0   4324  2048 ?        S    13:59   0:00 bash -c cd /app/large-scale-online-learning/ && source ../.python-venv/bin/activate && nohup locust -f /app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/locust-testing.py --users 50 --spawn-rate 50 --headless --csv=result_testing > locust.log 2>&1 &\n",
      "root        3795  100  1.1 1629532 376412 ?      Rl   13:59   0:45 /root/venv/bin/python3 /root/venv/bin/locust -f /app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/locust-testing.py --users 50 --spawn-rate 50 --headless --csv=result_testing\n",
      "root        3874 66.6  0.0   4324  3316 ?        Ss   14:00   0:00 bash -c ps aux | grep locust-testing.py\n",
      "root        3881  0.0  0.0   3528  1640 ?        S    14:00   0:00 grep locust-testing.py\n"
     ]
    }
   ],
   "source": [
    "# check whether the script is running\n",
    "run_docker_command(\"ps aux | grep check-kafka-lag.py\")\n",
    "run_docker_command(\"ps aux | grep locust-testing.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b67393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kill the process if it is running\n",
    "# run_docker_command(\"pkill -f check-kafka-lag.py\")\n",
    "# run_docker_command(\"pkill -f locust-testing.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e6ecf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1754895616.4320204,400\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF KAFKA LAG LOG IS GENERATED\n",
    "run_docker_command(\"cat /app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/kafka_lag_log.csv\")\n",
    "\n",
    "# clean kafka lag log\n",
    "# run_docker_command(\"rm -rf /app/large-scale-online-learning/MLOps-Architecture/Serialization_Datasets/kafka_lag_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd94485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF LOCUST LOGS ARE GENERATED\n",
    "run_docker_command(\"cat /app/large-scale-online-learning/locust.log\")\n",
    "\n",
    "# Clean up locust log\n",
    "# run_docker_command(\"rm -rf /app/large-scale-online-learning/locust.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Kubernetes pod is working\n",
    "# update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "# !kubectl exec {update_pods[0].split()[0]} -- ls\n",
    "# !kubectl exec {update_pods[0].split()[0]} -- cat message_log.csv\n",
    "\n",
    "# inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "# if inference_pods:\n",
    "#     print(f\"Inference pod found: {inference_pods[0]}\")\n",
    "#     !kubectl exec {inference_pods[0].split()[0]} -- ls\n",
    "#     !kubectl exec {inference_pods[0].split()[0]} -- cat message_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK Resource Usage of Load Testing VM\n",
    "!gcloud compute ssh load-testing-instance --zone=us-central1-a --command=\"top -b -n 1 | head -n 20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40249063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET VARIABLES\n",
    "with open(\"etc/variables.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith(\"#\"):\n",
    "            key, value = line.split(\"=\", 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            globals()[key] = value\n",
    "\n",
    "experiment = eval(experiment) if isinstance(experiment, str) else experiment\n",
    "if isinstance(experiment, list):\n",
    "    experiment_name = experiment[0]\n",
    "    experiment_file = experiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9848b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET INFERENCE RESULTS\n",
    "inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "if inference_pods:\n",
    "    filenames = !kubectl exec {inference_pods[0].split()[0]} -- ls | findstr /R \"load_model\"\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    !kubectl exec {inference_pods[0].split()[0]} -- tar -czf /app/{filename}.tar.gz /app/{filename}\n",
    "    !kubectl cp default/{inference_pods[0].split()[0]}:/app/{filename}.tar.gz experiment-results/{experiment_name}/inference-results/{filename}.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET UPDATE RESULTS\n",
    "pods = !kubectl get pods | findstr /R \"upd\"\n",
    "!kubectl exec {pods[0].split()[0]} -- tar -czf /app/for_auc.tar.gz /app/for_auc.csv\n",
    "!kubectl exec {pods[0].split()[0]} -- tar -czf /app/message_log.tar.gz /app/message_log.csv\n",
    "!kubectl exec {pods[0].split()[0]} -- tar -czf /app/model_upload_latency.tar.gz /app/model_upload_latency.csv\n",
    "!kubectl cp default/{pods[0].split()[0]}:/app/for_auc.tar.gz experiment-results/{experiment_name}/update-results/for_auc.tar.gz\n",
    "!kubectl cp default/{pods[0].split()[0]}:/app/message_log.tar.gz experiment-results/{experiment_name}/update-results/message_log.tar.gz\n",
    "!kubectl cp default/{pods[0].split()[0]}:/app/model_upload_latency.tar.gz experiment-results/{experiment_name}/update-results/model_upload_latency.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31335b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK MFLOW REPO\n",
    "!kubectl exec {pods[0].split()[0]} -- ls /mlartifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl exec {pods[0].split()[0]} -- tar -czf /mlartifacts/mlflow-results.tar.gz /mlartifacts/1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
