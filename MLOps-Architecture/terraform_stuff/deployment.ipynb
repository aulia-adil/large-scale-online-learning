{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f72ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for two-node-cluster.\n"
     ]
    }
   ],
   "source": [
    "projects = !gcloud config get-value project\n",
    "!gcloud config set project {projects[0]}\n",
    "!gcloud container clusters get-credentials two-node-cluster --zone us-central1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f8aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First node: gke-two-node-cluster-node-pool-1-260bb633-kp47\n",
      "Second node: gke-two-node-cluster-node-pool-1-260bb633-tgkc\n"
     ]
    }
   ],
   "source": [
    "# Get the nodes names\n",
    "nodes = !kubectl get nodes\n",
    "first_node = nodes[1].split()[0]\n",
    "second_node = nodes[2].split()[0]\n",
    "print(f\"First node: {first_node}\")\n",
    "print(f\"Second node: {second_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e728e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change node names in yaml files\n",
    "\n",
    "import yaml\n",
    "\n",
    "dir_yaml = 'deploy_real_kubernetes/'\n",
    "\n",
    "# FIRST NODE\n",
    "with open(dir_yaml + 'deploy_micro_inf.yaml', 'r') as filename:\n",
    "    micro_inf_configs = list(yaml.safe_load_all(filename))\n",
    "micro_inf_configs[0]['spec']['template']['spec']['nodeName'] = first_node\n",
    "with open(dir_yaml + 'deploy_micro_inf.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(micro_inf_configs, filename)\n",
    "\n",
    "with open(dir_yaml + '04-mlflow.yaml', 'r') as filename:\n",
    "    mlflow_configs = list(yaml.safe_load_all(filename))\n",
    "mlflow_configs[2]['spec']['template']['spec']['nodeName'] = first_node\n",
    "with open(dir_yaml + '04-mlflow.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(mlflow_configs, filename)\n",
    "\n",
    "# SECOND NODE\n",
    "with open(dir_yaml + '01-zookeeper.yaml', 'r') as filename:\n",
    "    zookeeper_configs = list(yaml.safe_load_all(filename))\n",
    "zookeeper_configs[1]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + '01-zookeeper.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(zookeeper_configs, filename)\n",
    "\n",
    "with open(dir_yaml + '02-kafka.yaml', 'r') as filename:\n",
    "    kafka_configs = list(yaml.safe_load_all(filename))\n",
    "kafka_configs[1]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + '02-kafka.yaml', 'w') as filename: \n",
    "    yaml.safe_dump_all(kafka_configs, filename)\n",
    "\n",
    "with open(dir_yaml + 'deploy_micro_up.yaml', 'r') as filename:\n",
    "    micro_up_configs = list(yaml.safe_load_all(filename))\n",
    "micro_up_configs[0]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + 'deploy_micro_up.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(micro_up_configs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f008f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying 00-namespace.yaml...\n",
      "namespace/kafka created\n",
      "Applying 01-zookeeper.yaml...\n",
      "service/zookeeper-service created\n",
      "deployment.apps/zookeeper created\n",
      "Applying 02-kafka.yaml...\n",
      "service/kafka-service created\n",
      "deployment.apps/kafka-broker created\n",
      "Applying 04-mlflow.yaml...\n",
      "persistentvolumeclaim/mlflow-pvc created\n",
      "service/mlflow created\n",
      "deployment.apps/mlflow created\n",
      "persistentvolume/mlflow-pv created\n",
      "Applying api_inference_svc.yaml...\n",
      "service/api-inferencia created\n",
      "Applying api_update_svc.yaml...\n",
      "service/api-update created\n",
      "Applying deploy_micro_inf.yaml...\n",
      "deployment.apps/api-inferencia created\n",
      "persistentvolumeclaim/api-inferencia-pvc created\n",
      "persistentvolume/api-inferencia-pv created\n",
      "Applying deploy_micro_up.yaml...\n",
      "deployment.apps/api-update created\n",
      "persistentvolumeclaim/api-update-pvc created\n",
      "persistentvolume/api-update-pv created\n",
      "Skipping node1.txt, not a YAML file.\n"
     ]
    }
   ],
   "source": [
    "# Apply yaml files\n",
    "dir_name = 'deploy_real_kubernetes'\n",
    "import os\n",
    "\n",
    "files = [f for f in os.listdir(dir_name) if os.path.isfile(os.path.join(dir_name, f))]\n",
    "for file in files:\n",
    "    if file.endswith('.yaml'):\n",
    "        print(f'Applying {file}...')\n",
    "        !kubectl apply -f {os.path.join(dir_name, file)}\n",
    "    else:\n",
    "        print(f'Skipping {file}, not a YAML file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd33f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Files to Pods\n",
    "\n",
    "# pods = !kubectl get pods | findstr /R \"upd\"\n",
    "\n",
    "# Check if pods are running\n",
    "# !kubectl exec {pods[0].split()[0]} -- ls /app/\n",
    "\n",
    "# pods = !kubectl get pods | findstr /R \"upd\"\n",
    "# !kubectl cp ../temp/upd/API_update_V8.1.py {pods[0].split()[0]}:/app/API_update_V8.1.py \n",
    "# !kubectl cp ../../Datasets/real_usage/AGR_a_first_train.csv {pods[0].split()[0]}:/app/AGR_a_first_train.csv\n",
    "# !kubectl cp ../../Datasets/real_usage/AGR_g_first_train.csv {pods[0].split()[0]}:/app/AGR_g_first_train.csv\n",
    "\n",
    "pods = !kubectl get pods | findstr /R \"inf\"\n",
    "!kubectl cp ../temp/inf/API_inferencia_V8.0.py {pods[0].split()[0]}:/app/API_inferencia_V8.0.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scripts\n",
    "\n",
    "import os\n",
    "import threading\n",
    "\n",
    "update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "\n",
    "def run_update_script(pod_name):\n",
    "    os.system(f\"kubectl exec {pod_name} -- nohup python3 /app/API_update_V8.1.py > NUL 2>&1 &\")\n",
    "t = threading.Thread(target=run_update_script, args=(update_pods[0].split()[0],))\n",
    "t.start()\n",
    "\n",
    "def run_inference_script(pod_name, script_path):\n",
    "    os.system(f\"kubectl exec {pod_name} -- nohup python3 {script_path} > NUL 2>&1 &\")\n",
    "\n",
    "inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "for pod in inference_pods:\n",
    "    pod_name = pod.split()[0]\n",
    "    script_path = \"/app/API_inferencia_V8.0.py\"\n",
    "    t = threading.Thread(target=run_inference_script, args=(pod_name, script_path))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02ed006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [SKIP] Kill the scripts\n",
    "for pod in inference_pods:\n",
    "    !kubectl exec {pod.split()[0]} -- pkill -f API\n",
    "for pod in update_pods:\n",
    "    !kubectl exec {pod.split()[0]} -- pkill -f API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9783507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Python processes in pods:\n",
      "Pod: api-inferencia-6f47cb7df8-92lbg\n",
      "Pod: api-inferencia-6f47cb7df8-dxnqj\n",
      "Pod: api-inferencia-6f47cb7df8-sp8t6\n",
      "Pod: api-inferencia-6f47cb7df8-tn9f8\n",
      "Pod: api-update-794765cdd7-wwk5f\n"
     ]
    }
   ],
   "source": [
    "# See python processes running in the pod\n",
    "# update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "# inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "print(\"Checking Python processes in pods:\")\n",
    "for pod in inference_pods:\n",
    "    print(f\"Pod: {pod.split()[0]}\")\n",
    "    !kubectl exec {pod.split()[0]} -- ps aux | findstr /R \"python\"\n",
    "\n",
    "for pod in update_pods:\n",
    "    print(f\"Pod: {pod.split()[0]}\")\n",
    "    !kubectl exec {pod.split()[0]} -- ps aux | findstr /R \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a211a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if program is working\n",
    "# update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "# !kubectl exec {update_pods[0].split()[0]} -- ls\n",
    "# !kubectl exec {update_pods[0].split()[0]} -- cat message_log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308a546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
