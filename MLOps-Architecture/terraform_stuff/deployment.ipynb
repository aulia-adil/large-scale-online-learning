{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f72ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for two-node-cluster.\n"
     ]
    }
   ],
   "source": [
    "projects = !gcloud config get-value project\n",
    "!gcloud config set project {projects[0]}\n",
    "!gcloud container clusters get-credentials two-node-cluster --zone us-central1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f8aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First node: gke-two-node-cluster-node-pool-1-93990693-mr7z\n",
      "Second node: gke-two-node-cluster-node-pool-1-93990693-vkd4\n"
     ]
    }
   ],
   "source": [
    "# Get the nodes names\n",
    "nodes = !kubectl get nodes\n",
    "first_node = nodes[1].split()[0]\n",
    "second_node = nodes[2].split()[0]\n",
    "print(f\"First node: {first_node}\")\n",
    "print(f\"Second node: {second_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e728e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change node names in yaml files\n",
    "\n",
    "import yaml\n",
    "\n",
    "dir_yaml = 'deploy_real_kubernetes/'\n",
    "\n",
    "# FIRST NODE\n",
    "with open(dir_yaml + 'deploy_micro_inf.yaml', 'r') as filename:\n",
    "    micro_inf_configs = list(yaml.safe_load_all(filename))\n",
    "micro_inf_configs[0]['spec']['template']['spec']['nodeName'] = first_node\n",
    "with open(dir_yaml + 'deploy_micro_inf.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(micro_inf_configs, filename)\n",
    "\n",
    "with open(dir_yaml + '04-mlflow.yaml', 'r') as filename:\n",
    "    mlflow_configs = list(yaml.safe_load_all(filename))\n",
    "mlflow_configs[2]['spec']['template']['spec']['nodeName'] = first_node\n",
    "with open(dir_yaml + '04-mlflow.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(mlflow_configs, filename)\n",
    "\n",
    "# SECOND NODE\n",
    "with open(dir_yaml + '01-zookeeper.yaml', 'r') as filename:\n",
    "    zookeeper_configs = list(yaml.safe_load_all(filename))\n",
    "zookeeper_configs[1]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + '01-zookeeper.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(zookeeper_configs, filename)\n",
    "\n",
    "with open(dir_yaml + '02-kafka.yaml', 'r') as filename:\n",
    "    kafka_configs = list(yaml.safe_load_all(filename))\n",
    "kafka_configs[1]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + '02-kafka.yaml', 'w') as filename: \n",
    "    yaml.safe_dump_all(kafka_configs, filename)\n",
    "\n",
    "with open(dir_yaml + 'deploy_micro_up.yaml', 'r') as filename:\n",
    "    micro_up_configs = list(yaml.safe_load_all(filename))\n",
    "micro_up_configs[0]['spec']['template']['spec']['nodeName'] = second_node\n",
    "with open(dir_yaml + 'deploy_micro_up.yaml', 'w') as filename:\n",
    "    yaml.safe_dump_all(micro_up_configs, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f008f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying 00-namespace.yaml...\n",
      "namespace/kafka created\n",
      "Applying 01-zookeeper.yaml...\n",
      "service/zookeeper-service created\n",
      "deployment.apps/zookeeper created\n",
      "Applying 02-kafka.yaml...\n",
      "service/kafka-service created\n",
      "deployment.apps/kafka-broker created\n",
      "Applying 04-mlflow.yaml...\n",
      "persistentvolumeclaim/mlflow-pvc created\n",
      "service/mlflow created\n",
      "deployment.apps/mlflow created\n",
      "Applying api_inference_svc.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error from server: error when creating \"deploy_real_kubernetes\\\\04-mlflow.yaml\": admission webhook \"warden-mutating.common-webhooks.networking.gke.io\" denied the request: GKE Warden rejected the request because it violates one or more mutators.\n",
      "Violations details: [\"error querying GCE PD volume mlflow-disk: disk is not found\"]\n",
      "Requested by user: 'AdilMuhammad706@gmail.com', groups: 'system:authenticated'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/api-inferencia created\n",
      "Applying api_update_svc.yaml...\n",
      "service/api-update created\n",
      "Applying deploy_micro_inf.yaml...\n",
      "deployment.apps/api-inferencia created\n",
      "persistentvolumeclaim/api-inferencia-pvc created\n",
      "Applying deploy_micro_up.yaml...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error from server: error when creating \"deploy_real_kubernetes\\\\deploy_micro_inf.yaml\": admission webhook \"warden-mutating.common-webhooks.networking.gke.io\" denied the request: GKE Warden rejected the request because it violates one or more mutators.\n",
      "Violations details: [\"error querying GCE PD volume api-update-disk: disk is not found\"]\n",
      "Requested by user: 'AdilMuhammad706@gmail.com', groups: 'system:authenticated'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/api-update created\n",
      "persistentvolumeclaim/api-update-pvc created\n",
      "Skipping node1.txt, not a YAML file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error from server: error when creating \"deploy_real_kubernetes\\\\deploy_micro_up.yaml\": admission webhook \"warden-mutating.common-webhooks.networking.gke.io\" denied the request: GKE Warden rejected the request because it violates one or more mutators.\n",
      "Violations details: [\"error querying GCE PD volume api-update-disk: disk is not found\"]\n",
      "Requested by user: 'AdilMuhammad706@gmail.com', groups: 'system:authenticated'.\n"
     ]
    }
   ],
   "source": [
    "# Apply yaml files\n",
    "dir_name = 'deploy_real_kubernetes'\n",
    "import os\n",
    "\n",
    "files = [f for f in os.listdir(dir_name) if os.path.isfile(os.path.join(dir_name, f))]\n",
    "for file in files:\n",
    "    if file.endswith('.yaml'):\n",
    "        print(f'Applying {file}...')\n",
    "        !kubectl apply -f {os.path.join(dir_name, file)}\n",
    "    else:\n",
    "        print(f'Skipping {file}, not a YAML file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efd33f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Files to Pods\n",
    "\n",
    "# pods = !kubectl get pods | findstr /R \"upd\"\n",
    "\n",
    "# Check if pods are running\n",
    "# !kubectl exec {pods[0].split()[0]} -- ls /app/\n",
    "\n",
    "pods = !kubectl get pods | findstr /R \"upd\"\n",
    "# !kubectl cp ../temp/upd/API_update_V8.1.py {pods[0].split()[0]}:/app/API_update_V8.1.py \n",
    "!kubectl cp ../temp/upd/API_update_V8.1_HT.py {pods[0].split()[0]}:/app/API_update_V8.1_HT.py \n",
    "# !kubectl cp ../temp/upd/API_update_V8.1_debug.py {pods[0].split()[0]}:/app/API_update_V8.1_debug.py \n",
    "# !kubectl cp ../../Datasets/real_usage/AGR_a_first_train.csv {pods[0].split()[0]}:/app/AGR_a_first_train.csv\n",
    "# !kubectl cp ../../Datasets/real_usage/AGR_g_first_train.csv {pods[0].split()[0]}:/app/AGR_g_first_train.csv\n",
    "\n",
    "# pods = !kubectl get pods | findstr /R \"inf\"\n",
    "# !kubectl cp ../temp/inf/API_inferencia_V8.0.py {pods[0].split()[0]}:/app/API_inferencia_V8.0.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9674ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scripts\n",
    "\n",
    "import os\n",
    "import threading\n",
    "\n",
    "# update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "\n",
    "# def run_update_script(pod_name):\n",
    "#     os.system(f\"kubectl exec {pod_name} -- nohup python3 /app/API_update_V8.1_HT.py > NUL 2>&1 &\")\n",
    "#     # os.system(f\"kubectl exec {pod_name} -- nohup python3 /app/API_update_V8.1.py > NUL 2>&1 &\")\n",
    "# t = threading.Thread(target=run_update_script, args=(update_pods[0].split()[0],))\n",
    "# t.start()\n",
    "\n",
    "def run_inference_script(pod_name, script_path):\n",
    "    os.system(f\"kubectl exec {pod_name} -- nohup python3 {script_path} > NUL 2>&1 &\")\n",
    "\n",
    "inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "for pod in inference_pods:\n",
    "    pod_name = pod.split()[0]\n",
    "    script_path = \"/app/API_inferencia_V8.0.py\"\n",
    "    t = threading.Thread(target=run_inference_script, args=(pod_name, script_path))\n",
    "    t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4517f067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service \"kafka-service\" deleted\n",
      "deployment.apps \"kafka-broker\" deleted\n",
      "service/kafka-service created\n",
      "deployment.apps/kafka-broker created\n"
     ]
    }
   ],
   "source": [
    "# RESTART KAFKA\n",
    "!kubectl delete -f deploy_real_kubernetes/02-kafka.yaml\n",
    "!kubectl apply -f deploy_real_kubernetes/02-kafka.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01aaac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Kafka pod: kafka-broker-7d45898578-q5nm5\n",
      "Status: 'Running'\n",
      "Kafka pod kafka-broker-7d45898578-q5nm5 is running.\n"
     ]
    }
   ],
   "source": [
    "# Health check for Kafka pod\n",
    "\n",
    "# Get Kafka pods\n",
    "kafka_pods = !kubectl get pods -n kafka | findstr /R \"kafka\"\n",
    "\n",
    "if kafka_pods:\n",
    "    for pod in kafka_pods:\n",
    "        pod_name = pod.split()[0]\n",
    "        print(f\"Checking Kafka pod: {pod_name}\")\n",
    "        command = \"kubectl get pod {} -n kafka -o jsonpath='{{.status.phase}}'\".format(pod_name)\n",
    "        status = !{command}\n",
    "        print(f\"Status: {status[0]}\")\n",
    "        if status[0].strip(\"'\") == \"Running\":\n",
    "            print(f\"Kafka pod {pod_name} is running.\")\n",
    "        else:\n",
    "            print(f\"Kafka pod {pod_name} is NOT running.\")\n",
    "else:\n",
    "    print(\"No Kafka pods found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d02ed006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [SKIP] Kill the scripts\n",
    "inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "for pod in inference_pods:\n",
    "    !kubectl exec {pod.split()[0]} -- pkill -f API\n",
    "for pod in update_pods:\n",
    "    !kubectl exec {pod.split()[0]} -- pkill -f API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9783507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Python processes in pods:\n",
      "Pod: api-inferencia-6688fcd87d-242pw\n",
      "root          20 10.1  0.5 5064128 187940 ?      Ssl  04:19   3:00 python3 /app/API_inferencia_V8.0.py\n",
      "Pod: api-update-59d77fff5f-zf9zt\n",
      "root          65 11.8  0.6 1211968 230060 ?      Ssl  04:19   3:32 python3 /app/API_update_V8.1.py\n",
      "root        2604  0.0  0.0      0     0 ?        Z    04:33   0:00 [python3] <defunct>\n",
      "root        2622  0.0  0.0      0     0 ?        Z    04:33   0:00 [python3] <defunct>\n",
      "root        2640  0.0  0.0      0     0 ?        Z    04:33   0:00 [python3] <defunct>\n"
     ]
    }
   ],
   "source": [
    "# See python processes running in the pod\n",
    "update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "inference_pods = !kubectl get pods | findstr /R \"inf\"\n",
    "print(\"Checking Python processes in pods:\")\n",
    "# for pod in inference_pods:\n",
    "#     print(f\"Pod: {pod.split()[0]}\")\n",
    "#     !kubectl exec {pod.split()[0]} -- ps aux | findstr /R \"python\"\n",
    "print(f\"Pod: {inference_pods[0].split()[0]}\")\n",
    "!kubectl exec {inference_pods[0].split()[0]} -- ps aux | findstr /R \"python\"\n",
    "\n",
    "\n",
    "for pod in update_pods:\n",
    "    print(f\"Pod: {pod.split()[0]}\")\n",
    "    !kubectl exec {pod.split()[0]} -- ps aux | findstr /R \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44a211a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGR_a_first_train.csv\n",
      "AGR_g_first_train.csv\n",
      "API_update_V8.1.py\n",
      "api_update.log\n",
      "lost+found\n"
     ]
    }
   ],
   "source": [
    "# Check if program is working\n",
    "update_pods = !kubectl get pods | findstr /R \"upd\"\n",
    "!kubectl exec {update_pods[0].split()[0]} -- ls\n",
    "# !kubectl exec {update_pods[0].split()[0]} -- cat api_update.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3308a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting instance(s) load-testing-instance...\n",
      "...........................................................................................done.\n",
      "Updated [https://compute.googleapis.com/compute/v1/projects/fast-learner-project/zones/us-central1-a/instances/load-testing-instance].\n",
      "Instance internal IP is 10.128.0.17\n",
      "Instance external IP is 104.197.3.201\n"
     ]
    }
   ],
   "source": [
    "# RUN LOAD TESTING INSTANCE VM\n",
    "!gcloud compute instances start load-testing-instance --zone=us-central1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44cef466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load-testing-container\n"
     ]
    }
   ],
   "source": [
    "# RUN LOAD TESTING CONTAINER\n",
    "# docker_command = \"docker start -d --name load-testing-container auliadil/load-testing-rodrigues:v1 tail -f /dev/null\"\n",
    "docker_command = \"docker start load-testing-container\"\n",
    "gcloud_template = \"gcloud compute ssh load-testing-instance --zone=us-central1-a\"\n",
    "!{gcloud_template} --command=\"{docker_command}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6124b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                                COMMAND               CREATED       STATUS          PORTS     NAMES\n",
      "032ca7df2590   auliadil/load-testing-rodrigues:v1   \"tail -f /dev/null\"   10 days ago   Up 22 seconds             load-testing-container\n"
     ]
    }
   ],
   "source": [
    "# CHECK IF CONTAINER IS RUNNING\n",
    "zone = \"us-central1-a\"\n",
    "!gcloud compute ssh load-testing-instance --zone={zone} --command=\"docker ps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f38d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping instance(s) load-testing-instance...\n",
      ".....................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Updated [https://compute.googleapis.com/compute/v1/projects/fast-learner-project/zones/us-central1-a/instances/load-testing-instance].\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!gcloud compute instances stop load-testing-instance --zone=us-central1-a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
